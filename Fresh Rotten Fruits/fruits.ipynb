{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayed-Husain/Image-Classification-Projects/blob/main/Fresh%20Rotten%20Fruits/fruits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HIAwTmDVXYy"
      },
      "source": [
        "# Image Classification: Fresh and Rotten Fruits Classification\n",
        "\n",
        "In this notebook, we are going to bulid a deep learning computer vision to model to classify fruits into categories: \n",
        "1. fresh apples\n",
        "2. fresh bananas\n",
        "3. fresh oranges\n",
        "4. rotten apples\n",
        "5. rotten bananas\n",
        "6. rotten oranges\n",
        "\n",
        "The dataset comes from [Kaggle](https://www.kaggle.com/sriramr/fruits-fresh-and-rotten-for-classification)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyAy4bi0dejd"
      },
      "outputs": [],
      "source": [
        "!unzip /content/data.zip -d /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct6aRgSRV5rS"
      },
      "source": [
        "## Load ImageNet Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xaepzqaYFqb",
        "outputId": "323d56a4-7a59-4944-a75e-5415a3e22e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "base_model = keras.applications.VGG16(\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "stdGF0a6YGAs"
      },
      "outputs": [],
      "source": [
        "# Freeze base model\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc0BlNHaYIXd"
      },
      "source": [
        "## Add Layers to Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ex4Ptx0JYJlY"
      },
      "outputs": [],
      "source": [
        "# Create inputs with correct shape\n",
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "# Add pooling layer or flatten layer\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Add final dense layer\n",
        "outputs = keras.layers.Dense(6, activation = 'softmax')(x)\n",
        "\n",
        "# Combine inputs and outputs to create model\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t095en-KYNTw",
        "outputId": "fdc9e122-c443-4b16-b5ef-543c5b2f37ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,717,766\n",
            "Trainable params: 3,078\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjYag64HYPiT"
      },
      "source": [
        "## Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DWUSFhGQYRkG"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUX0dfmtYdjD"
      },
      "source": [
        "## Augment the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Er-oJXEhYgAT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        samplewise_center=True,  # set each sample mean to 0\n",
        "        rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD2Tuv3mYjhU"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC7RKpu1Yjxq",
        "outputId": "474e5a92-09d7-44d9-ca33-b1c43d292256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1112 images belonging to 6 classes.\n",
            "Found 323 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "# load and iterate training dataset\n",
        "train_it = datagen.flow_from_directory(\"data/fruits/train/\", \n",
        "                                       target_size=(224, 224), \n",
        "                                       color_mode='rgb', \n",
        "                                       class_mode=\"categorical\")\n",
        "# load and iterate validation dataset\n",
        "valid_it = datagen.flow_from_directory(\"data/fruits/valid/\", \n",
        "                                      target_size=(224, 224), \n",
        "                                      color_mode='rgb', \n",
        "                                      class_mode=\"categorical\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwGP2R7QYnQH"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfmxXjLpYopt",
        "outputId": "22c3a499-94fe-4d94-8321-85c91ab104ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "34/34 [==============================] - 23s 635ms/step - loss: 1.4745 - accuracy: 0.5027 - val_loss: 0.7582 - val_accuracy: 0.7554\n",
            "Epoch 2/30\n",
            "34/34 [==============================] - 21s 619ms/step - loss: 0.5374 - accuracy: 0.8534 - val_loss: 0.4638 - val_accuracy: 0.8638\n",
            "Epoch 3/30\n",
            "34/34 [==============================] - 21s 615ms/step - loss: 0.3471 - accuracy: 0.9074 - val_loss: 0.3457 - val_accuracy: 0.8916\n",
            "Epoch 4/30\n",
            "34/34 [==============================] - 21s 609ms/step - loss: 0.2779 - accuracy: 0.9254 - val_loss: 0.2976 - val_accuracy: 0.9040\n",
            "Epoch 5/30\n",
            "34/34 [==============================] - 21s 614ms/step - loss: 0.2354 - accuracy: 0.9379 - val_loss: 0.2587 - val_accuracy: 0.9164\n",
            "Epoch 6/30\n",
            "34/34 [==============================] - 21s 613ms/step - loss: 0.2134 - accuracy: 0.9460 - val_loss: 0.2390 - val_accuracy: 0.9133\n",
            "Epoch 7/30\n",
            "34/34 [==============================] - 21s 612ms/step - loss: 0.1882 - accuracy: 0.9505 - val_loss: 0.2118 - val_accuracy: 0.9319\n",
            "Epoch 8/30\n",
            "34/34 [==============================] - 22s 633ms/step - loss: 0.1683 - accuracy: 0.9523 - val_loss: 0.2005 - val_accuracy: 0.9412\n",
            "Epoch 9/30\n",
            "34/34 [==============================] - 21s 612ms/step - loss: 0.1558 - accuracy: 0.9622 - val_loss: 0.2011 - val_accuracy: 0.9381\n",
            "Epoch 10/30\n",
            "34/34 [==============================] - 21s 612ms/step - loss: 0.1449 - accuracy: 0.9640 - val_loss: 0.1805 - val_accuracy: 0.9598\n",
            "Epoch 11/30\n",
            "34/34 [==============================] - 21s 614ms/step - loss: 0.1457 - accuracy: 0.9631 - val_loss: 0.1791 - val_accuracy: 0.9505\n",
            "Epoch 12/30\n",
            "34/34 [==============================] - 21s 617ms/step - loss: 0.1353 - accuracy: 0.9676 - val_loss: 0.1913 - val_accuracy: 0.9319\n",
            "Epoch 13/30\n",
            "34/34 [==============================] - 21s 613ms/step - loss: 0.1223 - accuracy: 0.9649 - val_loss: 0.1715 - val_accuracy: 0.9536\n",
            "Epoch 14/30\n",
            "34/34 [==============================] - 21s 610ms/step - loss: 0.1140 - accuracy: 0.9748 - val_loss: 0.1630 - val_accuracy: 0.9443\n",
            "Epoch 15/30\n",
            "34/34 [==============================] - 21s 614ms/step - loss: 0.1089 - accuracy: 0.9730 - val_loss: 0.1638 - val_accuracy: 0.9536\n",
            "Epoch 16/30\n",
            "34/34 [==============================] - 21s 615ms/step - loss: 0.1066 - accuracy: 0.9757 - val_loss: 0.1447 - val_accuracy: 0.9536\n",
            "Epoch 17/30\n",
            "34/34 [==============================] - 22s 633ms/step - loss: 0.0982 - accuracy: 0.9802 - val_loss: 0.1398 - val_accuracy: 0.9474\n",
            "Epoch 18/30\n",
            "34/34 [==============================] - 21s 617ms/step - loss: 0.0984 - accuracy: 0.9784 - val_loss: 0.1428 - val_accuracy: 0.9567\n",
            "Epoch 19/30\n",
            "34/34 [==============================] - 21s 611ms/step - loss: 0.0948 - accuracy: 0.9784 - val_loss: 0.1232 - val_accuracy: 0.9721\n",
            "Epoch 20/30\n",
            "34/34 [==============================] - 21s 615ms/step - loss: 0.0865 - accuracy: 0.9820 - val_loss: 0.1450 - val_accuracy: 0.9690\n",
            "Epoch 21/30\n",
            "34/34 [==============================] - 21s 615ms/step - loss: 0.0929 - accuracy: 0.9775 - val_loss: 0.1271 - val_accuracy: 0.9690\n",
            "Epoch 22/30\n",
            "34/34 [==============================] - 21s 612ms/step - loss: 0.0830 - accuracy: 0.9838 - val_loss: 0.1141 - val_accuracy: 0.9721\n",
            "Epoch 23/30\n",
            "34/34 [==============================] - 21s 613ms/step - loss: 0.0844 - accuracy: 0.9802 - val_loss: 0.1384 - val_accuracy: 0.9628\n",
            "Epoch 24/30\n",
            "34/34 [==============================] - 21s 612ms/step - loss: 0.0796 - accuracy: 0.9793 - val_loss: 0.1226 - val_accuracy: 0.9659\n",
            "Epoch 25/30\n",
            "34/34 [==============================] - 21s 614ms/step - loss: 0.0796 - accuracy: 0.9847 - val_loss: 0.1414 - val_accuracy: 0.9505\n",
            "Epoch 26/30\n",
            "34/34 [==============================] - 21s 617ms/step - loss: 0.0770 - accuracy: 0.9820 - val_loss: 0.1228 - val_accuracy: 0.9628\n",
            "Epoch 27/30\n",
            "34/34 [==============================] - 22s 628ms/step - loss: 0.0796 - accuracy: 0.9784 - val_loss: 0.1196 - val_accuracy: 0.9752\n",
            "Epoch 28/30\n",
            "34/34 [==============================] - 21s 612ms/step - loss: 0.0717 - accuracy: 0.9892 - val_loss: 0.1428 - val_accuracy: 0.9536\n",
            "Epoch 29/30\n",
            "34/34 [==============================] - 21s 616ms/step - loss: 0.0698 - accuracy: 0.9865 - val_loss: 0.1381 - val_accuracy: 0.9690\n",
            "Epoch 30/30\n",
            "34/34 [==============================] - 21s 612ms/step - loss: 0.0725 - accuracy: 0.9811 - val_loss: 0.1304 - val_accuracy: 0.9567\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efbaa300c10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model.fit(train_it,\n",
        "          validation_data=valid_it,\n",
        "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
        "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
        "          epochs=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6oB8guNYp0f"
      },
      "source": [
        "## Unfreeze Model for Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "i6oAN--3Yr0G"
      },
      "outputs": [],
      "source": [
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Compile the model with a low learning rate\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = keras.optimizers.RMSprop(learning_rate = 0.00005),\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "uKMrty8dYzKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9ba425-3824-4be6-d25c-be96e8defe4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/45\n",
            "34/34 [==============================] - 27s 731ms/step - loss: 0.4206 - accuracy: 0.9649 - val_loss: 0.1324 - val_accuracy: 0.9690\n",
            "Epoch 32/45\n",
            "34/34 [==============================] - 25s 712ms/step - loss: 0.0996 - accuracy: 0.9739 - val_loss: 0.0736 - val_accuracy: 0.9752\n",
            "Epoch 33/45\n",
            "34/34 [==============================] - 25s 706ms/step - loss: 0.1279 - accuracy: 0.9712 - val_loss: 0.0478 - val_accuracy: 0.9845\n",
            "Epoch 34/45\n",
            "34/34 [==============================] - 25s 714ms/step - loss: 0.1165 - accuracy: 0.9694 - val_loss: 0.0605 - val_accuracy: 0.9845\n",
            "Epoch 35/45\n",
            "34/34 [==============================] - 25s 710ms/step - loss: 0.0811 - accuracy: 0.9757 - val_loss: 0.0619 - val_accuracy: 0.9876\n",
            "Epoch 36/45\n",
            "34/34 [==============================] - 25s 728ms/step - loss: 0.1031 - accuracy: 0.9784 - val_loss: 0.0737 - val_accuracy: 0.9814\n",
            "Epoch 37/45\n",
            "34/34 [==============================] - 25s 715ms/step - loss: 0.0845 - accuracy: 0.9883 - val_loss: 0.0273 - val_accuracy: 0.9876\n",
            "Epoch 38/45\n",
            "34/34 [==============================] - 25s 709ms/step - loss: 0.2814 - accuracy: 0.9649 - val_loss: 0.2494 - val_accuracy: 0.9288\n",
            "Epoch 39/45\n",
            "34/34 [==============================] - 25s 710ms/step - loss: 0.0363 - accuracy: 0.9910 - val_loss: 0.0634 - val_accuracy: 0.9845\n",
            "Epoch 40/45\n",
            "34/34 [==============================] - 25s 716ms/step - loss: 0.1387 - accuracy: 0.9766 - val_loss: 0.1017 - val_accuracy: 0.9567\n",
            "Epoch 41/45\n",
            "34/34 [==============================] - 25s 707ms/step - loss: 0.0353 - accuracy: 0.9865 - val_loss: 0.0297 - val_accuracy: 0.9876\n",
            "Epoch 42/45\n",
            "34/34 [==============================] - 25s 710ms/step - loss: 0.3926 - accuracy: 0.9766 - val_loss: 0.1465 - val_accuracy: 0.9659\n",
            "Epoch 43/45\n",
            "34/34 [==============================] - 25s 711ms/step - loss: 0.0564 - accuracy: 0.9892 - val_loss: 0.4600 - val_accuracy: 0.9505\n",
            "Epoch 44/45\n",
            "34/34 [==============================] - 25s 714ms/step - loss: 0.1090 - accuracy: 0.9766 - val_loss: 0.3170 - val_accuracy: 0.9783\n",
            "Epoch 45/45\n",
            "34/34 [==============================] - 25s 715ms/step - loss: 0.0263 - accuracy: 0.9937 - val_loss: 0.0377 - val_accuracy: 0.9814\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efbaa101fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model.fit(train_it,\n",
        "          validation_data=valid_it,\n",
        "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
        "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
        "          epochs=45,\n",
        "          initial_epoch=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy2cM3CuY1KV"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HWR0Bd7YY11t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f380ac-1f9e-4b93-9dd7-d91cc3429bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 5s 471ms/step - loss: 0.0443 - accuracy: 0.9845\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04426585137844086, 0.9845201373100281]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "model.evaluate(valid_it, steps=valid_it.samples/valid_it.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IWizwKSOXNB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTpeqjJPZVkq6xZYiYu7h+",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}